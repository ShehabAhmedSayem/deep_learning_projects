{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Solutions\n",
    "## Problem 1\n",
    "Implement the Min-Max scaling function ($X'=a+{\\frac {\\left(X-X_{\\min }\\right)\\left(b-a\\right)}{X_{\\max }-X_{\\min }}}$) with the parameters:\n",
    "\n",
    "$X_{\\min }=0$\n",
    "\n",
    "$X_{\\max }=255$\n",
    "\n",
    "$a=0.1$\n",
    "\n",
    "$b=0.9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Problem 1 - Implement Min-Max scaling for grayscale image data\n",
    "def normalize_grayscale(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    a = 0.1\n",
    "    b = 0.9\n",
    "    grayscale_min = 0\n",
    "    grayscale_max = 255\n",
    "    return a + ( ( (image_data - grayscale_min)*(b - a) )/( grayscale_max - grayscale_min ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "- Use [tf.placeholder()](https://www.tensorflow.org/api_docs/python/io_ops.html#placeholder) for `features` and `labels` since they are the inputs to the model.\n",
    "- Any math operations must have the same type on both sides of the operator.  The weights are float32, so the `features` and `labels` must also be float32.\n",
    "- Use [tf.Variable()](https://www.tensorflow.org/api_docs/python/state_ops.html#Variable) to allow `weights` and `biases` to be modified.\n",
    "- The `weights` must be the dimensions of features by labels.  The number of features is the size of the image, 28*28=784.  The size of labels is 10.\n",
    "- The `biases` must be the dimensions of the labels, which is 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_count = 784\n",
    "labels_count = 10\n",
    "\n",
    "# Problem 2 - Set the features and labels tensors\n",
    "features = tf.placeholder(tf.float32)\n",
    "labels = tf.placeholder(tf.float32)\n",
    "\n",
    "# Problem 2 - Set the weights and biases tensors\n",
    "weights = tf.Variable(tf.truncated_normal((features_count, labels_count)))\n",
    "biases = tf.Variable(tf.zeros(labels_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "Configuration 1\n",
    "* **Epochs:** 1\n",
    "* **Learning Rate:** 0.1\n",
    "\n",
    "Configuration 2\n",
    "* **Epochs:** 4 or 5\n",
    "* **Learning Rate:** 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  PRICE  \n",
      "0     15.3  396.90   4.98   24.0  \n",
      "1     17.8  396.90   9.14   21.6  \n",
      "2     17.8  392.83   4.03   34.7  \n",
      "3     18.7  394.63   2.94   33.4  \n",
      "4     18.7  396.90   5.33   36.2  \n",
      "(455, 13)\n",
      "(455, 1)\n",
      "(51, 13)\n",
      "(51, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sayem/Softwares/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:52: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#data process\n",
    "\n",
    "data = pd.read_csv('boston_data.csv')\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "X = data.drop('PRICE', axis=1)\n",
    "Y = data['PRICE']\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size=0.1, random_state=5)\n",
    "\n",
    "\n",
    "# Scale data (training set) to 0 mean and unit standard deviation.\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "Y_train = np.reshape(Y_train, (-1,1)) \n",
    "Y_test = np.reshape(Y_test, (-1,1)) \n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Model\n",
    "\n",
    "def multilayer_perceptron(x, weights, biases, keep_prob):\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_1 = tf.nn.dropout(layer_1, keep_prob)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_2 = tf.nn.dropout(layer_2, keep_prob)\n",
    "    \n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "# Parameters\n",
    "\n",
    "n_input = 13\n",
    "n_hidden1_neuron = 64\n",
    "n_hidden2_neuron = 32\n",
    "n_output = 1\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden1_neuron], dtype=tf.float64)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden1_neuron, n_hidden2_neuron], dtype=tf.float64)),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden2_neuron, n_output], dtype=tf.float64))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden1_neuron], dtype=tf.float64)),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden2_neuron], dtype=tf.float64)),\n",
    "    'out': tf.Variable(tf.random_normal([n_output], dtype=tf.float64))\n",
    "}\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float64)\n",
    "\n",
    "x = tf.placeholder(tf.float64, [None, n_input])\n",
    "y = tf.placeholder(tf.float64, [None, n_output])\n",
    "\n",
    "predictions = multilayer_perceptron(x, weights, biases, keep_prob)\n",
    "cost = tf.reduce_mean(tf.square(predictions - y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 15546.655942631\n",
      "Epoch: 1001 cost= 5117.850639369\n",
      "Epoch: 2001 cost= 2823.797064499\n",
      "Epoch: 3001 cost= 1821.928060657\n",
      "Epoch: 4001 cost= 948.214079242\n",
      "Epoch: 5001 cost= 576.224294012\n",
      "Epoch: 6001 cost= 301.586612681\n",
      "Epoch: 7001 cost= 212.129743772\n",
      "Epoch: 8001 cost= 140.856030000\n",
      "Epoch: 9001 cost= 118.586782983\n",
      "Epoch: 10001 cost= 86.690393683\n",
      "Epoch: 11001 cost= 76.419554096\n",
      "Epoch: 12001 cost= 69.475534653\n",
      "Epoch: 13001 cost= 60.558455828\n",
      "Epoch: 14001 cost= 53.932501438\n",
      "Epoch: 15001 cost= 58.788160718\n",
      "Epoch: 16001 cost= 43.972921647\n",
      "Epoch: 17001 cost= 40.911072892\n",
      "Epoch: 18001 cost= 35.480294935\n",
      "Epoch: 19001 cost= 37.869513195\n",
      "Epoch: 20001 cost= 31.927721404\n",
      "Epoch: 21001 cost= 33.271771557\n",
      "Epoch: 22001 cost= 26.717421942\n",
      "Epoch: 23001 cost= 24.709612871\n",
      "Epoch: 24001 cost= 29.842921277\n",
      "Epoch: 25001 cost= 29.780801626\n",
      "Epoch: 26001 cost= 30.430211325\n",
      "Epoch: 27001 cost= 25.635674961\n",
      "Epoch: 28001 cost= 30.324274765\n",
      "Epoch: 29001 cost= 23.737305746\n",
      "Epoch: 30001 cost= 29.439797912\n",
      "Epoch: 31001 cost= 23.149890038\n",
      "Epoch: 32001 cost= 25.548692169\n",
      "Epoch: 33001 cost= 22.535244432\n",
      "Epoch: 34001 cost= 18.641586135\n",
      "Epoch: 35001 cost= 19.979913327\n",
      "Epoch: 36001 cost= 19.021457019\n",
      "Epoch: 37001 cost= 19.710071733\n",
      "Epoch: 38001 cost= 20.209675610\n",
      "Epoch: 39001 cost= 22.268219559\n",
      "Epoch: 40001 cost= 17.645836664\n",
      "Epoch: 41001 cost= 20.521728644\n",
      "Epoch: 42001 cost= 17.192914284\n",
      "Epoch: 43001 cost= 17.193978772\n",
      "Epoch: 44001 cost= 20.007647025\n",
      "Epoch: 45001 cost= 18.180498237\n",
      "Epoch: 46001 cost= 17.066057018\n",
      "Epoch: 47001 cost= 18.891364055\n",
      "Epoch: 48001 cost= 16.860119533\n",
      "Epoch: 49001 cost= 13.747386460\n",
      "Mean Squared Error of test data =  8.621800601\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "training_epochs = 50000\n",
    "display_step = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        \n",
    "        _, c = sess.run([optimizer, cost],\n",
    "                        feed_dict={\n",
    "                            x: X_train,\n",
    "                            y: Y_train,\n",
    "                            keep_prob: 0.8\n",
    "                        })\n",
    "        \n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                    \"{:.9f}\".format(c))\n",
    "    \n",
    "    _, test_c = sess.run([optimizer, cost],\n",
    "                        feed_dict={\n",
    "                            x: X_test,\n",
    "                            y: Y_test,\n",
    "                            keep_prob: 1\n",
    "                        })\n",
    "    print(\"Mean Squared Error of test data = \", \"{:.9f}\".format(test_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralnet_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: -34.85 (34.37) MSE\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('boston_data.csv')\n",
    "\n",
    "#print(data.head())\n",
    "\n",
    "X = data.drop('PRICE', axis=1)\n",
    "Y = data['PRICE']\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=neuralnet_model, epochs=200, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
    "y = np.array([1, 1, 2, 2])\n",
    "\n",
    "clf = SVC(kernel=\"rbf\", C=\"\")\n",
    "clf.fit(X,Y)\n",
    "clf.predict([[-0.8, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
